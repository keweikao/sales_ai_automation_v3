/**
 * æ¸¬è©¦ Whisper è½‰éŒ„åŠŸèƒ½ - åˆ†æ®µè™•ç†å¤§æª”æ¡ˆ
 *
 * é€™å€‹è…³æœ¬æœƒ:
 * 1. å°‡å¤§éŸ³æª”åˆ‡å‰²æˆå¤šå€‹ < 25MB çš„ç‰‡æ®µ
 * 2. åˆ†åˆ¥è½‰éŒ„æ¯å€‹ç‰‡æ®µ
 * 3. åˆä½µè½‰éŒ„çµæœ
 */

import { exec } from "node:child_process";
import { readFile, writeFile } from "node:fs/promises";
import { resolve } from "node:path";
import { promisify } from "node:util";

const execAsync = promisify(exec);

// å¾ç’°å¢ƒè®Šæ•¸è®€å– API Key
const GROQ_API_KEY = process.env.GROQ_API_KEY || "";

if (!GROQ_API_KEY) {
  console.error("âŒ éŒ¯èª¤: è«‹è¨­å®š GROQ_API_KEY ç’°å¢ƒè®Šæ•¸");
  process.exit(1);
}

const CHUNK_DURATION = 600; // æ¯æ®µ 10 åˆ†é˜
const _MAX_FILE_SIZE_MB = 20; // ç›®æ¨™å¤§å° < 25MB

async function getAudioDuration(audioPath: string): Promise<number> {
  const { stdout } = await execAsync(
    `ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 "${audioPath}"`
  );
  return Number.parseFloat(stdout.trim());
}

async function splitAudio(
  audioPath: string,
  outputDir: string
): Promise<string[]> {
  console.log("\nâœ‚ï¸  åˆ‡å‰²éŸ³æª”...");

  const duration = await getAudioDuration(audioPath);
  console.log(`   ç¸½é•·åº¦: ${(duration / 60).toFixed(2)} åˆ†é˜`);

  const numChunks = Math.ceil(duration / CHUNK_DURATION);
  console.log(
    `   å°‡åˆ‡å‰²æˆ ${numChunks} å€‹ç‰‡æ®µ (æ¯æ®µ ${CHUNK_DURATION / 60} åˆ†é˜)`
  );

  const chunkPaths: string[] = [];

  for (let i = 0; i < numChunks; i++) {
    const startTime = i * CHUNK_DURATION;
    const chunkPath = resolve(outputDir, `chunk_${i + 1}.mp3`);

    console.log(`   åˆ‡å‰²ç‰‡æ®µ ${i + 1}/${numChunks}...`);

    await execAsync(
      `ffmpeg -i "${audioPath}" -ss ${startTime} -t ${CHUNK_DURATION} -ab 32k -ar 16000 -ac 1 "${chunkPath}" -y 2>&1 | grep -v "^frame="`
    );

    chunkPaths.push(chunkPath);
  }

  console.log(`   âœ“ å®Œæˆåˆ‡å‰² ${chunkPaths.length} å€‹ç‰‡æ®µ`);
  return chunkPaths;
}

async function transcribeChunk(
  chunkPath: string,
  chunkIndex: number
): Promise<any> {
  console.log(`\nğŸ¤ è½‰éŒ„ç‰‡æ®µ ${chunkIndex}...`);

  const audioBuffer = await readFile(chunkPath);
  const fileSizeMB = (audioBuffer.length / 1024 / 1024).toFixed(2);
  console.log(`   å¤§å°: ${fileSizeMB} MB`);

  const formData = new FormData();
  formData.append(
    "file",
    new Blob([audioBuffer], { type: "audio/mpeg" }),
    `chunk_${chunkIndex}.mp3`
  );
  formData.append("model", "whisper-large-v3-turbo");
  formData.append("response_format", "verbose_json");
  formData.append("language", "zh");

  const startTime = Date.now();

  const response = await fetch(
    "https://api.groq.com/openai/v1/audio/transcriptions",
    {
      method: "POST",
      headers: {
        Authorization: `Bearer ${GROQ_API_KEY}`,
      },
      body: formData,
    }
  );

  const elapsed = ((Date.now() - startTime) / 1000).toFixed(2);

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`è½‰éŒ„å¤±æ•— (${response.status}): ${errorText}`);
  }

  const result = await response.json();
  console.log(`   âœ“ å®Œæˆ! (è€—æ™‚: ${elapsed} ç§’)`);

  return result;
}

async function mergeTranscriptions(transcriptions: any[]): Promise<any> {
  console.log("\nğŸ”— åˆä½µè½‰éŒ„çµæœ...");

  let fullText = "";
  const allSegments: any[] = [];
  let timeOffset = 0;

  for (let i = 0; i < transcriptions.length; i++) {
    const trans = transcriptions[i];

    // åˆä½µæ–‡å­—
    fullText += `${trans.text} `;

    // åˆä½µç‰‡æ®µ,èª¿æ•´æ™‚é–“æˆ³
    if (trans.segments) {
      for (const segment of trans.segments) {
        allSegments.push({
          ...segment,
          start: segment.start + timeOffset,
          end: segment.end + timeOffset,
        });
      }

      // æ›´æ–°æ™‚é–“åç§»
      const lastSegment = trans.segments.at(-1);
      if (lastSegment) {
        timeOffset += lastSegment.end;
      }
    }
  }

  console.log(`   âœ“ åˆä½µ ${transcriptions.length} å€‹ç‰‡æ®µ`);
  console.log(`   âœ“ ç¸½å…± ${allSegments.length} å€‹å¥å­ç‰‡æ®µ`);

  return {
    text: fullText.trim(),
    segments: allSegments,
  };
}

async function testChunkedTranscription() {
  console.log("ğŸ§ª æ¸¬è©¦åˆ†æ®µ Whisper è½‰éŒ„");
  console.log("=".repeat(60));

  try {
    const audioPath = resolve(__dirname, "../çŸ¥äº‹å®˜é‚¸ - æ¢æ˜å‡±.mp3");
    const tempDir = resolve(__dirname, "../temp-chunks");

    // å‰µå»ºè‡¨æ™‚ç›®éŒ„
    await execAsync(`mkdir -p "${tempDir}"`);

    // æ­¥é©Ÿ 1: åˆ‡å‰²éŸ³æª”
    const chunkPaths = await splitAudio(audioPath, tempDir);

    // æ­¥é©Ÿ 2: è½‰éŒ„æ¯å€‹ç‰‡æ®µ
    const transcriptions: any[] = [];

    for (let i = 0; i < chunkPaths.length; i++) {
      const result = await transcribeChunk(chunkPaths[i], i + 1);
      transcriptions.push(result);
    }

    // æ­¥é©Ÿ 3: åˆä½µçµæœ
    const finalResult = await mergeTranscriptions(transcriptions);

    // æ­¥é©Ÿ 4: é¡¯ç¤ºçµæœ
    console.log(`\n${"=".repeat(60)}`);
    console.log("âœ… è½‰éŒ„å®Œæˆ!");
    console.log("=".repeat(60));

    console.log("\nğŸ“ å®Œæ•´è½‰éŒ„æ–‡å­—:");
    console.log(finalResult.text);

    console.log(`\nğŸ“Š å…± ${finalResult.segments.length} å€‹å¥å­ç‰‡æ®µ`);

    // é¡¯ç¤ºå‰ 10 å€‹ç‰‡æ®µ
    console.log("\nå‰ 10 å€‹ç‰‡æ®µ:");
    console.log("=".repeat(60));

    finalResult.segments
      .slice(0, 10)
      .forEach((segment: any, _index: number) => {
        const startTime = segment.start.toFixed(2);
        const endTime = segment.end.toFixed(2);
        console.log(`\n[${startTime}s - ${endTime}s]:`);
        console.log(`  ${segment.text}`);
      });

    // å„²å­˜å®Œæ•´çµæœ
    const outputPath = resolve(__dirname, "../transcription-result.json");
    await writeFile(outputPath, JSON.stringify(finalResult, null, 2));
    console.log(`\nğŸ’¾ å®Œæ•´çµæœå·²å„²å­˜è‡³: ${outputPath}`);

    // æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
    console.log("\nğŸ§¹ æ¸…ç†è‡¨æ™‚æª”æ¡ˆ...");
    await execAsync(`rm -rf "${tempDir}"`);

    console.log(`\n${"=".repeat(60)}`);
    console.log("âœ… æ¸¬è©¦å®Œæˆ!");
  } catch (error) {
    console.error("\nâŒ æ¸¬è©¦å¤±æ•—:");
    console.error(error);
    process.exit(1);
  }
}

// åŸ·è¡Œæ¸¬è©¦
testChunkedTranscription();
